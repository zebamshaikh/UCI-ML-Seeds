{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2e110834e11fcf5500f4dd9e5f72b5b8",
     "grade": false,
     "grade_id": "cell-80b77fe0d5d362ae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Explain the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a3ae4a44207d40f055e076aabbb09b45",
     "grade": true,
     "grade_id": "cell-e573d055cfb4a916",
     "locked": false,
     "points": 4,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "The “tradeoff” between bias and variance can be viewed in this manner – a learning algorithm with low bias must be “flexible” so that it can fit the data well. But if the learning algorithm is too flexible (for instance, too linear), it will fit each training data set differently, and hence have high variance. A key characteristic of many supervised learning methods is a built-in way to control the bias-variance tradeoff either automatically or by providing a special parameter that the data scientist can adjust.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "83886665b6d5458966acb332c5e17c68",
     "grade": false,
     "grade_id": "cell-c40be3d158eb9ad1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Discuss the pros and cons of using the BIC to select a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "25405a06bb3615c01ebf2da1294c49a8",
     "grade": true,
     "grade_id": "cell-5df930a8f675836a",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "Pros:\n",
    "-BIC is better in situations where a false positive is as misleading as, or more misleading than, a false negative.\n",
    "\n",
    "Cons:\n",
    "\n",
    "-BIC is only valid for sample size n much larger than the number of parameters k in the model.\n",
    "-BIC cannot handle complex collections of models as in the feature selection problem in high-dimension.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection on a Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data = read.csv(\"data/iris.csv\", row.names='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ('area',\"perimeter\",\"compactness\",\"length of kernel\",\n",
    "                   \"width of kernel\",\"assymetry coefficient\",\"length of kernel groove\",\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDS_DATA_URL <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt'\n",
    "seeds.data <- read.table(SEEDS_DATA_URL,header=FALSE,sep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>area</th><th scope=col>perimeter</th><th scope=col>compactness</th><th scope=col>length_of_kernel</th><th scope=col>width_of_kernel</th><th scope=col>assymetry_coefficient</th><th scope=col>length_of_kernel_groove</th><th scope=col>target</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>15.26 </td><td>14.84 </td><td>0.8710</td><td>5.763 </td><td>3.312 </td><td>2.2210</td><td>5.220 </td><td>1     </td></tr>\n",
       "\t<tr><td>14.88 </td><td>14.57 </td><td>0.8811</td><td>5.554 </td><td>3.333 </td><td>1.0180</td><td>4.956 </td><td>1     </td></tr>\n",
       "\t<tr><td>14.29 </td><td>14.09 </td><td>0.9050</td><td>5.291 </td><td>3.337 </td><td>2.6990</td><td>4.825 </td><td>1     </td></tr>\n",
       "\t<tr><td>13.84 </td><td>13.94 </td><td>0.8955</td><td>5.324 </td><td>3.379 </td><td>2.2590</td><td>4.805 </td><td>1     </td></tr>\n",
       "\t<tr><td>16.14 </td><td>14.99 </td><td>0.9034</td><td>5.658 </td><td>3.562 </td><td>1.3550</td><td>5.175 </td><td>1     </td></tr>\n",
       "\t<tr><td>14.38 </td><td>14.21 </td><td>0.8951</td><td>5.386 </td><td>3.312 </td><td>2.4620</td><td>4.956 </td><td>1     </td></tr>\n",
       "\t<tr><td>14.69 </td><td>14.49 </td><td>0.8799</td><td>5.563 </td><td>3.259 </td><td>3.5860</td><td>5.219 </td><td>1     </td></tr>\n",
       "\t<tr><td>14.11 </td><td>14.10 </td><td>0.8911</td><td>5.420 </td><td>3.302 </td><td>2.7000</td><td>5.000 </td><td>1     </td></tr>\n",
       "\t<tr><td>16.63 </td><td>15.46 </td><td>0.8747</td><td>6.053 </td><td>3.465 </td><td>2.0400</td><td>5.877 </td><td>1     </td></tr>\n",
       "\t<tr><td>16.44 </td><td>15.25 </td><td>0.8880</td><td>5.884 </td><td>3.505 </td><td>1.9690</td><td>5.533 </td><td>1     </td></tr>\n",
       "\t<tr><td>15.26 </td><td>14.85 </td><td>0.8696</td><td>5.714 </td><td>3.242 </td><td>4.5430</td><td>5.314 </td><td>1     </td></tr>\n",
       "\t<tr><td>14.03 </td><td>14.16 </td><td>0.8796</td><td>5.438 </td><td>3.201 </td><td>1.7170</td><td>5.001 </td><td>1     </td></tr>\n",
       "\t<tr><td>13.89 </td><td>14.02 </td><td>0.8880</td><td>5.439 </td><td>3.199 </td><td>3.9860</td><td>4.738 </td><td>1     </td></tr>\n",
       "\t<tr><td>13.78 </td><td>14.06 </td><td>0.8759</td><td>5.479 </td><td>3.156 </td><td>3.1360</td><td>4.872 </td><td>1     </td></tr>\n",
       "\t<tr><td>13.74 </td><td>14.05 </td><td>0.8744</td><td>5.482 </td><td>3.114 </td><td>2.9320</td><td>4.825 </td><td>1     </td></tr>\n",
       "\t<tr><td>14.59 </td><td>14.28 </td><td>0.8993</td><td>5.351 </td><td>3.333 </td><td>4.1850</td><td>4.781 </td><td>1     </td></tr>\n",
       "\t<tr><td>13.99 </td><td>13.83 </td><td>0.9183</td><td>5.119 </td><td>3.383 </td><td>5.2340</td><td>4.781 </td><td>1     </td></tr>\n",
       "\t<tr><td>15.69 </td><td>14.75 </td><td>0.9058</td><td>5.527 </td><td>3.514 </td><td>1.5990</td><td>5.046 </td><td>1     </td></tr>\n",
       "\t<tr><td>14.70 </td><td>14.21 </td><td>0.9153</td><td>5.205 </td><td>3.466 </td><td>1.7670</td><td>4.649 </td><td>1     </td></tr>\n",
       "\t<tr><td>12.72 </td><td>13.57 </td><td>0.8686</td><td>5.226 </td><td>3.049 </td><td>4.1020</td><td>4.914 </td><td>1     </td></tr>\n",
       "\t<tr><td>14.16 </td><td>14.40 </td><td>0.8584</td><td>5.658 </td><td>3.129 </td><td>3.0720</td><td>5.176 </td><td>1     </td></tr>\n",
       "\t<tr><td>14.11 </td><td>14.26 </td><td>0.8722</td><td>5.520 </td><td>3.168 </td><td>2.6880</td><td>5.219 </td><td>1     </td></tr>\n",
       "\t<tr><td>15.88 </td><td>14.90 </td><td>0.8988</td><td>5.618 </td><td>3.507 </td><td>0.7651</td><td>5.091 </td><td>1     </td></tr>\n",
       "\t<tr><td>12.08 </td><td>13.23 </td><td>0.8664</td><td>5.099 </td><td>2.936 </td><td>1.4150</td><td>4.961 </td><td>1     </td></tr>\n",
       "\t<tr><td>15.01 </td><td>14.76 </td><td>0.8657</td><td>5.789 </td><td>3.245 </td><td>1.7910</td><td>5.001 </td><td>1     </td></tr>\n",
       "\t<tr><td>16.19 </td><td>15.16 </td><td>0.8849</td><td>5.833 </td><td>3.421 </td><td>0.9030</td><td>5.307 </td><td>1     </td></tr>\n",
       "\t<tr><td>13.02 </td><td>13.76 </td><td>0.8641</td><td>5.395 </td><td>3.026 </td><td>3.3730</td><td>4.825 </td><td>1     </td></tr>\n",
       "\t<tr><td>12.74 </td><td>13.67 </td><td>0.8564</td><td>5.395 </td><td>2.956 </td><td>2.5040</td><td>4.869 </td><td>1     </td></tr>\n",
       "\t<tr><td>14.11 </td><td>14.18 </td><td>0.8820</td><td>5.541 </td><td>3.221 </td><td>2.7540</td><td>5.038 </td><td>1     </td></tr>\n",
       "\t<tr><td>13.45 </td><td>14.02 </td><td>0.8604</td><td>5.516 </td><td>3.065 </td><td>3.5310</td><td>5.097 </td><td>1     </td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>11.41 </td><td>12.95 </td><td>0.8560</td><td>5.090 </td><td>2.775 </td><td>4.957 </td><td>4.825 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.46 </td><td>13.41 </td><td>0.8706</td><td>5.236 </td><td>3.017 </td><td>4.987 </td><td>5.147 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.19 </td><td>13.36 </td><td>0.8579</td><td>5.240 </td><td>2.909 </td><td>4.857 </td><td>5.158 </td><td>3     </td></tr>\n",
       "\t<tr><td>11.65 </td><td>13.07 </td><td>0.8575</td><td>5.108 </td><td>2.850 </td><td>5.209 </td><td>5.135 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.89 </td><td>13.77 </td><td>0.8541</td><td>5.495 </td><td>3.026 </td><td>6.185 </td><td>5.316 </td><td>3     </td></tr>\n",
       "\t<tr><td>11.56 </td><td>13.31 </td><td>0.8198</td><td>5.363 </td><td>2.683 </td><td>4.062 </td><td>5.182 </td><td>3     </td></tr>\n",
       "\t<tr><td>11.81 </td><td>13.45 </td><td>0.8198</td><td>5.413 </td><td>2.716 </td><td>4.898 </td><td>5.352 </td><td>3     </td></tr>\n",
       "\t<tr><td>10.91 </td><td>12.80 </td><td>0.8372</td><td>5.088 </td><td>2.675 </td><td>4.179 </td><td>4.956 </td><td>3     </td></tr>\n",
       "\t<tr><td>11.23 </td><td>12.82 </td><td>0.8594</td><td>5.089 </td><td>2.821 </td><td>7.524 </td><td>4.957 </td><td>3     </td></tr>\n",
       "\t<tr><td>10.59 </td><td>12.41 </td><td>0.8648</td><td>4.899 </td><td>2.787 </td><td>4.975 </td><td>4.794 </td><td>3     </td></tr>\n",
       "\t<tr><td>10.93 </td><td>12.80 </td><td>0.8390</td><td>5.046 </td><td>2.717 </td><td>5.398 </td><td>5.045 </td><td>3     </td></tr>\n",
       "\t<tr><td>11.27 </td><td>12.86 </td><td>0.8563</td><td>5.091 </td><td>2.804 </td><td>3.985 </td><td>5.001 </td><td>3     </td></tr>\n",
       "\t<tr><td>11.87 </td><td>13.02 </td><td>0.8795</td><td>5.132 </td><td>2.953 </td><td>3.597 </td><td>5.132 </td><td>3     </td></tr>\n",
       "\t<tr><td>10.82 </td><td>12.83 </td><td>0.8256</td><td>5.180 </td><td>2.630 </td><td>4.853 </td><td>5.089 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.11 </td><td>13.27 </td><td>0.8639</td><td>5.236 </td><td>2.975 </td><td>4.132 </td><td>5.012 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.80 </td><td>13.47 </td><td>0.8860</td><td>5.160 </td><td>3.126 </td><td>4.873 </td><td>4.914 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.79 </td><td>13.53 </td><td>0.8786</td><td>5.224 </td><td>3.054 </td><td>5.483 </td><td>4.958 </td><td>3     </td></tr>\n",
       "\t<tr><td>13.37 </td><td>13.78 </td><td>0.8849</td><td>5.320 </td><td>3.128 </td><td>4.670 </td><td>5.091 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.62 </td><td>13.67 </td><td>0.8481</td><td>5.410 </td><td>2.911 </td><td>3.306 </td><td>5.231 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.76 </td><td>13.38 </td><td>0.8964</td><td>5.073 </td><td>3.155 </td><td>2.828 </td><td>4.830 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.38 </td><td>13.44 </td><td>0.8609</td><td>5.219 </td><td>2.989 </td><td>5.472 </td><td>5.045 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.67 </td><td>13.32 </td><td>0.8977</td><td>4.984 </td><td>3.135 </td><td>2.300 </td><td>4.745 </td><td>3     </td></tr>\n",
       "\t<tr><td>11.18 </td><td>12.72 </td><td>0.8680</td><td>5.009 </td><td>2.810 </td><td>4.051 </td><td>4.828 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.70 </td><td>13.41 </td><td>0.8874</td><td>5.183 </td><td>3.091 </td><td>8.456 </td><td>5.000 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.37 </td><td>13.47 </td><td>0.8567</td><td>5.204 </td><td>2.960 </td><td>3.919 </td><td>5.001 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.19 </td><td>13.20 </td><td>0.8783</td><td>5.137 </td><td>2.981 </td><td>3.631 </td><td>4.870 </td><td>3     </td></tr>\n",
       "\t<tr><td>11.23 </td><td>12.88 </td><td>0.8511</td><td>5.140 </td><td>2.795 </td><td>4.325 </td><td>5.003 </td><td>3     </td></tr>\n",
       "\t<tr><td>13.20 </td><td>13.66 </td><td>0.8883</td><td>5.236 </td><td>3.232 </td><td>8.315 </td><td>5.056 </td><td>3     </td></tr>\n",
       "\t<tr><td>11.84 </td><td>13.21 </td><td>0.8521</td><td>5.175 </td><td>2.836 </td><td>3.598 </td><td>5.044 </td><td>3     </td></tr>\n",
       "\t<tr><td>12.30 </td><td>13.34 </td><td>0.8684</td><td>5.243 </td><td>2.974 </td><td>5.637 </td><td>5.063 </td><td>3     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       " area & perimeter & compactness & length\\_of\\_kernel & width\\_of\\_kernel & assymetry\\_coefficient & length\\_of\\_kernel\\_groove & target\\\\\n",
       "\\hline\n",
       "\t 15.26  & 14.84  & 0.8710 & 5.763  & 3.312  & 2.2210 & 5.220  & 1     \\\\\n",
       "\t 14.88  & 14.57  & 0.8811 & 5.554  & 3.333  & 1.0180 & 4.956  & 1     \\\\\n",
       "\t 14.29  & 14.09  & 0.9050 & 5.291  & 3.337  & 2.6990 & 4.825  & 1     \\\\\n",
       "\t 13.84  & 13.94  & 0.8955 & 5.324  & 3.379  & 2.2590 & 4.805  & 1     \\\\\n",
       "\t 16.14  & 14.99  & 0.9034 & 5.658  & 3.562  & 1.3550 & 5.175  & 1     \\\\\n",
       "\t 14.38  & 14.21  & 0.8951 & 5.386  & 3.312  & 2.4620 & 4.956  & 1     \\\\\n",
       "\t 14.69  & 14.49  & 0.8799 & 5.563  & 3.259  & 3.5860 & 5.219  & 1     \\\\\n",
       "\t 14.11  & 14.10  & 0.8911 & 5.420  & 3.302  & 2.7000 & 5.000  & 1     \\\\\n",
       "\t 16.63  & 15.46  & 0.8747 & 6.053  & 3.465  & 2.0400 & 5.877  & 1     \\\\\n",
       "\t 16.44  & 15.25  & 0.8880 & 5.884  & 3.505  & 1.9690 & 5.533  & 1     \\\\\n",
       "\t 15.26  & 14.85  & 0.8696 & 5.714  & 3.242  & 4.5430 & 5.314  & 1     \\\\\n",
       "\t 14.03  & 14.16  & 0.8796 & 5.438  & 3.201  & 1.7170 & 5.001  & 1     \\\\\n",
       "\t 13.89  & 14.02  & 0.8880 & 5.439  & 3.199  & 3.9860 & 4.738  & 1     \\\\\n",
       "\t 13.78  & 14.06  & 0.8759 & 5.479  & 3.156  & 3.1360 & 4.872  & 1     \\\\\n",
       "\t 13.74  & 14.05  & 0.8744 & 5.482  & 3.114  & 2.9320 & 4.825  & 1     \\\\\n",
       "\t 14.59  & 14.28  & 0.8993 & 5.351  & 3.333  & 4.1850 & 4.781  & 1     \\\\\n",
       "\t 13.99  & 13.83  & 0.9183 & 5.119  & 3.383  & 5.2340 & 4.781  & 1     \\\\\n",
       "\t 15.69  & 14.75  & 0.9058 & 5.527  & 3.514  & 1.5990 & 5.046  & 1     \\\\\n",
       "\t 14.70  & 14.21  & 0.9153 & 5.205  & 3.466  & 1.7670 & 4.649  & 1     \\\\\n",
       "\t 12.72  & 13.57  & 0.8686 & 5.226  & 3.049  & 4.1020 & 4.914  & 1     \\\\\n",
       "\t 14.16  & 14.40  & 0.8584 & 5.658  & 3.129  & 3.0720 & 5.176  & 1     \\\\\n",
       "\t 14.11  & 14.26  & 0.8722 & 5.520  & 3.168  & 2.6880 & 5.219  & 1     \\\\\n",
       "\t 15.88  & 14.90  & 0.8988 & 5.618  & 3.507  & 0.7651 & 5.091  & 1     \\\\\n",
       "\t 12.08  & 13.23  & 0.8664 & 5.099  & 2.936  & 1.4150 & 4.961  & 1     \\\\\n",
       "\t 15.01  & 14.76  & 0.8657 & 5.789  & 3.245  & 1.7910 & 5.001  & 1     \\\\\n",
       "\t 16.19  & 15.16  & 0.8849 & 5.833  & 3.421  & 0.9030 & 5.307  & 1     \\\\\n",
       "\t 13.02  & 13.76  & 0.8641 & 5.395  & 3.026  & 3.3730 & 4.825  & 1     \\\\\n",
       "\t 12.74  & 13.67  & 0.8564 & 5.395  & 2.956  & 2.5040 & 4.869  & 1     \\\\\n",
       "\t 14.11  & 14.18  & 0.8820 & 5.541  & 3.221  & 2.7540 & 5.038  & 1     \\\\\n",
       "\t 13.45  & 14.02  & 0.8604 & 5.516  & 3.065  & 3.5310 & 5.097  & 1     \\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t 11.41  & 12.95  & 0.8560 & 5.090  & 2.775  & 4.957  & 4.825  & 3     \\\\\n",
       "\t 12.46  & 13.41  & 0.8706 & 5.236  & 3.017  & 4.987  & 5.147  & 3     \\\\\n",
       "\t 12.19  & 13.36  & 0.8579 & 5.240  & 2.909  & 4.857  & 5.158  & 3     \\\\\n",
       "\t 11.65  & 13.07  & 0.8575 & 5.108  & 2.850  & 5.209  & 5.135  & 3     \\\\\n",
       "\t 12.89  & 13.77  & 0.8541 & 5.495  & 3.026  & 6.185  & 5.316  & 3     \\\\\n",
       "\t 11.56  & 13.31  & 0.8198 & 5.363  & 2.683  & 4.062  & 5.182  & 3     \\\\\n",
       "\t 11.81  & 13.45  & 0.8198 & 5.413  & 2.716  & 4.898  & 5.352  & 3     \\\\\n",
       "\t 10.91  & 12.80  & 0.8372 & 5.088  & 2.675  & 4.179  & 4.956  & 3     \\\\\n",
       "\t 11.23  & 12.82  & 0.8594 & 5.089  & 2.821  & 7.524  & 4.957  & 3     \\\\\n",
       "\t 10.59  & 12.41  & 0.8648 & 4.899  & 2.787  & 4.975  & 4.794  & 3     \\\\\n",
       "\t 10.93  & 12.80  & 0.8390 & 5.046  & 2.717  & 5.398  & 5.045  & 3     \\\\\n",
       "\t 11.27  & 12.86  & 0.8563 & 5.091  & 2.804  & 3.985  & 5.001  & 3     \\\\\n",
       "\t 11.87  & 13.02  & 0.8795 & 5.132  & 2.953  & 3.597  & 5.132  & 3     \\\\\n",
       "\t 10.82  & 12.83  & 0.8256 & 5.180  & 2.630  & 4.853  & 5.089  & 3     \\\\\n",
       "\t 12.11  & 13.27  & 0.8639 & 5.236  & 2.975  & 4.132  & 5.012  & 3     \\\\\n",
       "\t 12.80  & 13.47  & 0.8860 & 5.160  & 3.126  & 4.873  & 4.914  & 3     \\\\\n",
       "\t 12.79  & 13.53  & 0.8786 & 5.224  & 3.054  & 5.483  & 4.958  & 3     \\\\\n",
       "\t 13.37  & 13.78  & 0.8849 & 5.320  & 3.128  & 4.670  & 5.091  & 3     \\\\\n",
       "\t 12.62  & 13.67  & 0.8481 & 5.410  & 2.911  & 3.306  & 5.231  & 3     \\\\\n",
       "\t 12.76  & 13.38  & 0.8964 & 5.073  & 3.155  & 2.828  & 4.830  & 3     \\\\\n",
       "\t 12.38  & 13.44  & 0.8609 & 5.219  & 2.989  & 5.472  & 5.045  & 3     \\\\\n",
       "\t 12.67  & 13.32  & 0.8977 & 4.984  & 3.135  & 2.300  & 4.745  & 3     \\\\\n",
       "\t 11.18  & 12.72  & 0.8680 & 5.009  & 2.810  & 4.051  & 4.828  & 3     \\\\\n",
       "\t 12.70  & 13.41  & 0.8874 & 5.183  & 3.091  & 8.456  & 5.000  & 3     \\\\\n",
       "\t 12.37  & 13.47  & 0.8567 & 5.204  & 2.960  & 3.919  & 5.001  & 3     \\\\\n",
       "\t 12.19  & 13.20  & 0.8783 & 5.137  & 2.981  & 3.631  & 4.870  & 3     \\\\\n",
       "\t 11.23  & 12.88  & 0.8511 & 5.140  & 2.795  & 4.325  & 5.003  & 3     \\\\\n",
       "\t 13.20  & 13.66  & 0.8883 & 5.236  & 3.232  & 8.315  & 5.056  & 3     \\\\\n",
       "\t 11.84  & 13.21  & 0.8521 & 5.175  & 2.836  & 3.598  & 5.044  & 3     \\\\\n",
       "\t 12.30  & 13.34  & 0.8684 & 5.243  & 2.974  & 5.637  & 5.063  & 3     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "area | perimeter | compactness | length_of_kernel | width_of_kernel | assymetry_coefficient | length_of_kernel_groove | target | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 15.26  | 14.84  | 0.8710 | 5.763  | 3.312  | 2.2210 | 5.220  | 1      | \n",
       "| 14.88  | 14.57  | 0.8811 | 5.554  | 3.333  | 1.0180 | 4.956  | 1      | \n",
       "| 14.29  | 14.09  | 0.9050 | 5.291  | 3.337  | 2.6990 | 4.825  | 1      | \n",
       "| 13.84  | 13.94  | 0.8955 | 5.324  | 3.379  | 2.2590 | 4.805  | 1      | \n",
       "| 16.14  | 14.99  | 0.9034 | 5.658  | 3.562  | 1.3550 | 5.175  | 1      | \n",
       "| 14.38  | 14.21  | 0.8951 | 5.386  | 3.312  | 2.4620 | 4.956  | 1      | \n",
       "| 14.69  | 14.49  | 0.8799 | 5.563  | 3.259  | 3.5860 | 5.219  | 1      | \n",
       "| 14.11  | 14.10  | 0.8911 | 5.420  | 3.302  | 2.7000 | 5.000  | 1      | \n",
       "| 16.63  | 15.46  | 0.8747 | 6.053  | 3.465  | 2.0400 | 5.877  | 1      | \n",
       "| 16.44  | 15.25  | 0.8880 | 5.884  | 3.505  | 1.9690 | 5.533  | 1      | \n",
       "| 15.26  | 14.85  | 0.8696 | 5.714  | 3.242  | 4.5430 | 5.314  | 1      | \n",
       "| 14.03  | 14.16  | 0.8796 | 5.438  | 3.201  | 1.7170 | 5.001  | 1      | \n",
       "| 13.89  | 14.02  | 0.8880 | 5.439  | 3.199  | 3.9860 | 4.738  | 1      | \n",
       "| 13.78  | 14.06  | 0.8759 | 5.479  | 3.156  | 3.1360 | 4.872  | 1      | \n",
       "| 13.74  | 14.05  | 0.8744 | 5.482  | 3.114  | 2.9320 | 4.825  | 1      | \n",
       "| 14.59  | 14.28  | 0.8993 | 5.351  | 3.333  | 4.1850 | 4.781  | 1      | \n",
       "| 13.99  | 13.83  | 0.9183 | 5.119  | 3.383  | 5.2340 | 4.781  | 1      | \n",
       "| 15.69  | 14.75  | 0.9058 | 5.527  | 3.514  | 1.5990 | 5.046  | 1      | \n",
       "| 14.70  | 14.21  | 0.9153 | 5.205  | 3.466  | 1.7670 | 4.649  | 1      | \n",
       "| 12.72  | 13.57  | 0.8686 | 5.226  | 3.049  | 4.1020 | 4.914  | 1      | \n",
       "| 14.16  | 14.40  | 0.8584 | 5.658  | 3.129  | 3.0720 | 5.176  | 1      | \n",
       "| 14.11  | 14.26  | 0.8722 | 5.520  | 3.168  | 2.6880 | 5.219  | 1      | \n",
       "| 15.88  | 14.90  | 0.8988 | 5.618  | 3.507  | 0.7651 | 5.091  | 1      | \n",
       "| 12.08  | 13.23  | 0.8664 | 5.099  | 2.936  | 1.4150 | 4.961  | 1      | \n",
       "| 15.01  | 14.76  | 0.8657 | 5.789  | 3.245  | 1.7910 | 5.001  | 1      | \n",
       "| 16.19  | 15.16  | 0.8849 | 5.833  | 3.421  | 0.9030 | 5.307  | 1      | \n",
       "| 13.02  | 13.76  | 0.8641 | 5.395  | 3.026  | 3.3730 | 4.825  | 1      | \n",
       "| 12.74  | 13.67  | 0.8564 | 5.395  | 2.956  | 2.5040 | 4.869  | 1      | \n",
       "| 14.11  | 14.18  | 0.8820 | 5.541  | 3.221  | 2.7540 | 5.038  | 1      | \n",
       "| 13.45  | 14.02  | 0.8604 | 5.516  | 3.065  | 3.5310 | 5.097  | 1      | \n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | \n",
       "| 11.41  | 12.95  | 0.8560 | 5.090  | 2.775  | 4.957  | 4.825  | 3      | \n",
       "| 12.46  | 13.41  | 0.8706 | 5.236  | 3.017  | 4.987  | 5.147  | 3      | \n",
       "| 12.19  | 13.36  | 0.8579 | 5.240  | 2.909  | 4.857  | 5.158  | 3      | \n",
       "| 11.65  | 13.07  | 0.8575 | 5.108  | 2.850  | 5.209  | 5.135  | 3      | \n",
       "| 12.89  | 13.77  | 0.8541 | 5.495  | 3.026  | 6.185  | 5.316  | 3      | \n",
       "| 11.56  | 13.31  | 0.8198 | 5.363  | 2.683  | 4.062  | 5.182  | 3      | \n",
       "| 11.81  | 13.45  | 0.8198 | 5.413  | 2.716  | 4.898  | 5.352  | 3      | \n",
       "| 10.91  | 12.80  | 0.8372 | 5.088  | 2.675  | 4.179  | 4.956  | 3      | \n",
       "| 11.23  | 12.82  | 0.8594 | 5.089  | 2.821  | 7.524  | 4.957  | 3      | \n",
       "| 10.59  | 12.41  | 0.8648 | 4.899  | 2.787  | 4.975  | 4.794  | 3      | \n",
       "| 10.93  | 12.80  | 0.8390 | 5.046  | 2.717  | 5.398  | 5.045  | 3      | \n",
       "| 11.27  | 12.86  | 0.8563 | 5.091  | 2.804  | 3.985  | 5.001  | 3      | \n",
       "| 11.87  | 13.02  | 0.8795 | 5.132  | 2.953  | 3.597  | 5.132  | 3      | \n",
       "| 10.82  | 12.83  | 0.8256 | 5.180  | 2.630  | 4.853  | 5.089  | 3      | \n",
       "| 12.11  | 13.27  | 0.8639 | 5.236  | 2.975  | 4.132  | 5.012  | 3      | \n",
       "| 12.80  | 13.47  | 0.8860 | 5.160  | 3.126  | 4.873  | 4.914  | 3      | \n",
       "| 12.79  | 13.53  | 0.8786 | 5.224  | 3.054  | 5.483  | 4.958  | 3      | \n",
       "| 13.37  | 13.78  | 0.8849 | 5.320  | 3.128  | 4.670  | 5.091  | 3      | \n",
       "| 12.62  | 13.67  | 0.8481 | 5.410  | 2.911  | 3.306  | 5.231  | 3      | \n",
       "| 12.76  | 13.38  | 0.8964 | 5.073  | 3.155  | 2.828  | 4.830  | 3      | \n",
       "| 12.38  | 13.44  | 0.8609 | 5.219  | 2.989  | 5.472  | 5.045  | 3      | \n",
       "| 12.67  | 13.32  | 0.8977 | 4.984  | 3.135  | 2.300  | 4.745  | 3      | \n",
       "| 11.18  | 12.72  | 0.8680 | 5.009  | 2.810  | 4.051  | 4.828  | 3      | \n",
       "| 12.70  | 13.41  | 0.8874 | 5.183  | 3.091  | 8.456  | 5.000  | 3      | \n",
       "| 12.37  | 13.47  | 0.8567 | 5.204  | 2.960  | 3.919  | 5.001  | 3      | \n",
       "| 12.19  | 13.20  | 0.8783 | 5.137  | 2.981  | 3.631  | 4.870  | 3      | \n",
       "| 11.23  | 12.88  | 0.8511 | 5.140  | 2.795  | 4.325  | 5.003  | 3      | \n",
       "| 13.20  | 13.66  | 0.8883 | 5.236  | 3.232  | 8.315  | 5.056  | 3      | \n",
       "| 11.84  | 13.21  | 0.8521 | 5.175  | 2.836  | 3.598  | 5.044  | 3      | \n",
       "| 12.30  | 13.34  | 0.8684 | 5.243  | 2.974  | 5.637  | 5.063  | 3      | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    area  perimeter compactness length_of_kernel width_of_kernel\n",
       "1   15.26 14.84     0.8710      5.763            3.312          \n",
       "2   14.88 14.57     0.8811      5.554            3.333          \n",
       "3   14.29 14.09     0.9050      5.291            3.337          \n",
       "4   13.84 13.94     0.8955      5.324            3.379          \n",
       "5   16.14 14.99     0.9034      5.658            3.562          \n",
       "6   14.38 14.21     0.8951      5.386            3.312          \n",
       "7   14.69 14.49     0.8799      5.563            3.259          \n",
       "8   14.11 14.10     0.8911      5.420            3.302          \n",
       "9   16.63 15.46     0.8747      6.053            3.465          \n",
       "10  16.44 15.25     0.8880      5.884            3.505          \n",
       "11  15.26 14.85     0.8696      5.714            3.242          \n",
       "12  14.03 14.16     0.8796      5.438            3.201          \n",
       "13  13.89 14.02     0.8880      5.439            3.199          \n",
       "14  13.78 14.06     0.8759      5.479            3.156          \n",
       "15  13.74 14.05     0.8744      5.482            3.114          \n",
       "16  14.59 14.28     0.8993      5.351            3.333          \n",
       "17  13.99 13.83     0.9183      5.119            3.383          \n",
       "18  15.69 14.75     0.9058      5.527            3.514          \n",
       "19  14.70 14.21     0.9153      5.205            3.466          \n",
       "20  12.72 13.57     0.8686      5.226            3.049          \n",
       "21  14.16 14.40     0.8584      5.658            3.129          \n",
       "22  14.11 14.26     0.8722      5.520            3.168          \n",
       "23  15.88 14.90     0.8988      5.618            3.507          \n",
       "24  12.08 13.23     0.8664      5.099            2.936          \n",
       "25  15.01 14.76     0.8657      5.789            3.245          \n",
       "26  16.19 15.16     0.8849      5.833            3.421          \n",
       "27  13.02 13.76     0.8641      5.395            3.026          \n",
       "28  12.74 13.67     0.8564      5.395            2.956          \n",
       "29  14.11 14.18     0.8820      5.541            3.221          \n",
       "30  13.45 14.02     0.8604      5.516            3.065          \n",
       "⋮   ⋮     ⋮         ⋮           ⋮                ⋮              \n",
       "181 11.41 12.95     0.8560      5.090            2.775          \n",
       "182 12.46 13.41     0.8706      5.236            3.017          \n",
       "183 12.19 13.36     0.8579      5.240            2.909          \n",
       "184 11.65 13.07     0.8575      5.108            2.850          \n",
       "185 12.89 13.77     0.8541      5.495            3.026          \n",
       "186 11.56 13.31     0.8198      5.363            2.683          \n",
       "187 11.81 13.45     0.8198      5.413            2.716          \n",
       "188 10.91 12.80     0.8372      5.088            2.675          \n",
       "189 11.23 12.82     0.8594      5.089            2.821          \n",
       "190 10.59 12.41     0.8648      4.899            2.787          \n",
       "191 10.93 12.80     0.8390      5.046            2.717          \n",
       "192 11.27 12.86     0.8563      5.091            2.804          \n",
       "193 11.87 13.02     0.8795      5.132            2.953          \n",
       "194 10.82 12.83     0.8256      5.180            2.630          \n",
       "195 12.11 13.27     0.8639      5.236            2.975          \n",
       "196 12.80 13.47     0.8860      5.160            3.126          \n",
       "197 12.79 13.53     0.8786      5.224            3.054          \n",
       "198 13.37 13.78     0.8849      5.320            3.128          \n",
       "199 12.62 13.67     0.8481      5.410            2.911          \n",
       "200 12.76 13.38     0.8964      5.073            3.155          \n",
       "201 12.38 13.44     0.8609      5.219            2.989          \n",
       "202 12.67 13.32     0.8977      4.984            3.135          \n",
       "203 11.18 12.72     0.8680      5.009            2.810          \n",
       "204 12.70 13.41     0.8874      5.183            3.091          \n",
       "205 12.37 13.47     0.8567      5.204            2.960          \n",
       "206 12.19 13.20     0.8783      5.137            2.981          \n",
       "207 11.23 12.88     0.8511      5.140            2.795          \n",
       "208 13.20 13.66     0.8883      5.236            3.232          \n",
       "209 11.84 13.21     0.8521      5.175            2.836          \n",
       "210 12.30 13.34     0.8684      5.243            2.974          \n",
       "    assymetry_coefficient length_of_kernel_groove target\n",
       "1   2.2210                5.220                   1     \n",
       "2   1.0180                4.956                   1     \n",
       "3   2.6990                4.825                   1     \n",
       "4   2.2590                4.805                   1     \n",
       "5   1.3550                5.175                   1     \n",
       "6   2.4620                4.956                   1     \n",
       "7   3.5860                5.219                   1     \n",
       "8   2.7000                5.000                   1     \n",
       "9   2.0400                5.877                   1     \n",
       "10  1.9690                5.533                   1     \n",
       "11  4.5430                5.314                   1     \n",
       "12  1.7170                5.001                   1     \n",
       "13  3.9860                4.738                   1     \n",
       "14  3.1360                4.872                   1     \n",
       "15  2.9320                4.825                   1     \n",
       "16  4.1850                4.781                   1     \n",
       "17  5.2340                4.781                   1     \n",
       "18  1.5990                5.046                   1     \n",
       "19  1.7670                4.649                   1     \n",
       "20  4.1020                4.914                   1     \n",
       "21  3.0720                5.176                   1     \n",
       "22  2.6880                5.219                   1     \n",
       "23  0.7651                5.091                   1     \n",
       "24  1.4150                4.961                   1     \n",
       "25  1.7910                5.001                   1     \n",
       "26  0.9030                5.307                   1     \n",
       "27  3.3730                4.825                   1     \n",
       "28  2.5040                4.869                   1     \n",
       "29  2.7540                5.038                   1     \n",
       "30  3.5310                5.097                   1     \n",
       "⋮   ⋮                     ⋮                       ⋮     \n",
       "181 4.957                 4.825                   3     \n",
       "182 4.987                 5.147                   3     \n",
       "183 4.857                 5.158                   3     \n",
       "184 5.209                 5.135                   3     \n",
       "185 6.185                 5.316                   3     \n",
       "186 4.062                 5.182                   3     \n",
       "187 4.898                 5.352                   3     \n",
       "188 4.179                 4.956                   3     \n",
       "189 7.524                 4.957                   3     \n",
       "190 4.975                 4.794                   3     \n",
       "191 5.398                 5.045                   3     \n",
       "192 3.985                 5.001                   3     \n",
       "193 3.597                 5.132                   3     \n",
       "194 4.853                 5.089                   3     \n",
       "195 4.132                 5.012                   3     \n",
       "196 4.873                 4.914                   3     \n",
       "197 5.483                 4.958                   3     \n",
       "198 4.670                 5.091                   3     \n",
       "199 3.306                 5.231                   3     \n",
       "200 2.828                 4.830                   3     \n",
       "201 5.472                 5.045                   3     \n",
       "202 2.300                 4.745                   3     \n",
       "203 4.051                 4.828                   3     \n",
       "204 8.456                 5.000                   3     \n",
       "205 3.919                 5.001                   3     \n",
       "206 3.631                 4.870                   3     \n",
       "207 4.325                 5.003                   3     \n",
       "208 8.315                 5.056                   3     \n",
       "209 3.598                 5.044                   3     \n",
       "210 5.637                 5.063                   3     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'list'"
      ],
      "text/latex": [
       "'list'"
      ],
      "text/markdown": [
       "'list'"
      ],
      "text/plain": [
       "[1] \"list\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seeds_df\n",
    "typeof(seeds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(seeds.data) =c(\"area\",\"perimeter\",\"compactness\",\"length_of_kernel\",\n",
    "                   \"width_of_kernel\",\"assymetry_coefficient\",\"length_of_kernel_groove\",\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = \"target ~ 1 + area + perimeter + compactness + length_of_kernel +\\n                            width_of_kernel + assymetry_coefficient + length_of_kernel_groove\", \n",
       "    data = seeds.data)\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-1.30568  -0.24785  -0.01632   0.24198   1.22362  \n",
       "\n",
       "Coefficients:\n",
       "                         Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)              53.44356    7.44511   7.178 1.32e-11 ***\n",
       "area                      1.48907    0.26133   5.698 4.25e-08 ***\n",
       "perimeter                -3.22038    0.53815  -5.984 9.77e-09 ***\n",
       "compactness             -30.67744    5.24108  -5.853 1.92e-08 ***\n",
       "length_of_kernel         -2.31510    0.45444  -5.094 8.01e-07 ***\n",
       "width_of_kernel           0.24598    0.78571   0.313    0.755    \n",
       "assymetry_coefficient     0.11489    0.02257   5.089 8.19e-07 ***\n",
       "length_of_kernel_groove   2.19260    0.20358  10.770  < 2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.1722565)\n",
       "\n",
       "    Null deviance: 140.000  on 209  degrees of freedom\n",
       "Residual deviance:  34.796  on 202  degrees of freedom\n",
       "AIC: 236.46\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seeds.glm = glm(\"target ~ 1 + area + perimeter + compactness + length_of_kernel +\n",
    "                            width_of_kernel + assymetry_coefficient + length_of_kernel_groove\", data = seeds.data)\n",
    "summary(seeds.glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Log-Likelihood\n",
    "\n",
    "Without going too far into the math, we can think of the log-likelihood as a **likelihood function** telling us how likely a model is given the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value is not human interpretable but is useful as a comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log Lik.' -109.228 (df=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logLik(seeds.glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"All models are wrong, but some are useful.\" - George Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might be concerned with one additional property - the **complexity** of the model. \n",
    "\n",
    "##### William of Occam\n",
    "\n",
    "[**Occam's razor**](https://en.wikipedia.org/wiki/Occam's_razor) is the problem-solving principle that, when presented with competing hypothetical answers to a problem, one should select the one that makes the fewest assumptions.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ab/William_of_Ockham_-_Logica_1341.jpg\" width=400px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent this idea of complexity in terms of both the number of features we use and the amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Information Criterion\n",
    "\n",
    "https://en.wikipedia.org/wiki/Bayesian_information_criterion\n",
    "\n",
    "The BIC is formally defined as\n",
    "\n",
    "$$ \\mathrm{BIC} = {\\ln(n)k - 2\\ln({\\widehat L})}. $$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\widehat L$ = the maximized value of the likelihood function of the model $M$\n",
    "- $x$ = the observed data\n",
    "- $n$ = the number of data points in $x$, the number of observations, or equivalently, the sample size;\n",
    "- $k$ = the number of parameters estimated by the model. For example, in multiple linear regression, the estimated parameters are the intercept, the $q$ slope parameters, and the constant variance of the errors; thus, $k = q + 2$.\n",
    "\n",
    "\n",
    "It might help us to think of it as \n",
    "\n",
    "$$ \\mathrm{BIC} = \\text{complexity}-\\text{likelihood}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "266.579917042231"
      ],
      "text/latex": [
       "266.579917042231"
      ],
      "text/markdown": [
       "266.579917042231"
      ],
      "text/plain": [
       "[1] 266.5799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BIC(seeds.glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log Lik.' 266.5799 (df=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = length(seeds.glm$fitted.values)\n",
    "p = length(coefficients(seeds.glm))\n",
    "\n",
    "likelihood = 2 * logLik(seeds.glm)\n",
    "complexity = log(n)*(p+1)\n",
    "\n",
    "bic = complexity - likelihood\n",
    "bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_of_model = function (model) {\n",
    "    n = length(model$fitted.values)\n",
    "    p = length(coefficients(model))\n",
    "\n",
    "    likelihood = 2 * logLik(model)\n",
    "    complexity = log(n)*(p+1)\n",
    "\n",
    "    bic = complexity - likelihood\n",
    "    return(bic)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log Lik.' 266.5799 (df=9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BIC_of_model(seeds.glm) #df below means degrees of freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "Here, we choose the optimal model by removing features one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_1  = \"target ~ 1 + area + perimeter + compactness + length_of_kernel + width_of_kernel + assymetry_coefficient + length_of_kernel_groove\"\n",
    "model_2a = \"target ~ 1 + area + perimeter + compactness + length_of_kernel + width_of_kernel + assymetry_coefficient\"\n",
    "model_2b = \"target ~ 1 + area + perimeter + compactness + length_of_kernel + width_of_kernel + length_of_kernel_groove\"\n",
    "model_2c = \"target ~ 1 + area + perimeter + compactness + length_of_kernel + assymetry_coefficient + length_of_kernel_groove\"\n",
    "model_2d = \"target ~ 1 + area + perimeter + compactness + width_of_kernel + assymetry_coefficient + length_of_kernel_groove\"\n",
    "model_2e = \"target ~ 1 + area + perimeter + length_of_kernel + width_of_kernel + assymetry_coefficient + length_of_kernel_groove\"\n",
    "model_2f = \"target ~ 1 + area + compactness + length_of_kernel + width_of_kernel + assymetry_coefficient + length_of_kernel_groove\"\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds.glm.1 = glm(model_1, data=seeds.data)\n",
    "seeds.glm.2a = glm(model_2a, data=seeds.data)\n",
    "seeds.glm.2b = glm(model_2b, data=seeds.data)\n",
    "seeds.glm.2c = glm(model_2c, data=seeds.data)\n",
    "seeds.glm.2d = glm(model_2d, data=seeds.data)\n",
    "seeds.glm.2e = glm(model_2e, data=seeds.data)\n",
    "seeds.glm.2f = glm(model_2f, data=seeds.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"model_1\"          \"266.579917042231\"\n",
      "[1] \"model_2a\"         \"356.525745573155\"\n",
      "[1] \"model_2b\"         \"286.569723996916\"\n",
      "[1] \"model_2c\"         \"261.334679806275\"\n",
      "[1] \"model_2d\"         \"286.615929930958\"\n",
      "[1] \"model_2e\"         \"294.133138313643\"\n",
      "[1] \"model_2f\"         \"295.505888618519\"\n"
     ]
    }
   ],
   "source": [
    "print(c('model_1', BIC_of_model(seeds.glm.1)))\n",
    "print(c('model_2a', BIC_of_model(seeds.glm.2a )))\n",
    "print(c('model_2b', BIC_of_model(seeds.glm.2b )))\n",
    "print(c('model_2c', BIC_of_model(seeds.glm.2c )))\n",
    "print(c('model_2d', BIC_of_model(seeds.glm.2d )))\n",
    "print(c('model_2e', BIC_of_model(seeds.glm.2e )))\n",
    "print(c('model_2f', BIC_of_model(seeds.glm.2f )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"model_1\"          \"266.579917042231\"\n",
      "[1] \"model_2a\"         \"356.525745573155\"\n",
      "[1] \"model_2b\"         \"286.569723996916\"\n",
      "[1] \"model_2c\"         \"261.334679806275\"\n",
      "[1] \"model_2d\"         \"286.615929930958\"\n",
      "[1] \"model_2e\"         \"294.133138313643\"\n",
      "[1] \"model_2f\"         \"295.505888618519\"\n"
     ]
    }
   ],
   "source": [
    "print(c('model_1', BIC(seeds.glm.1)))\n",
    "print(c('model_2a', BIC(seeds.glm.2a )))\n",
    "print(c('model_2b', BIC(seeds.glm.2b )))\n",
    "print(c('model_2c', BIC(seeds.glm.2c )))\n",
    "print(c('model_2d', BIC(seeds.glm.2d )))\n",
    "print(c('model_2e', BIC(seeds.glm.2e )))\n",
    "print(c('model_2f', BIC(seeds.glm.2f )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1  = \"target ~ 1 + area + perimeter + compactness + length_of_kernel + width_of_kernel + assymetry_coefficient + length_of_kernel_groove\"\n",
    "model_2c = \"target ~ 1 + area + perimeter + compactness + length_of_kernel + assymetry_coefficient + length_of_kernel_groove\"\n",
    "\n",
    "model_3a = \"target ~ 1 + area + compactness + width_of_kernel + assymetry_coefficient\"\n",
    "model_3b = \"target ~ 1 + area + perimeter + length_of_kernel + length_of_kernel_groove\"\n",
    "model_3c = \"target ~ 1 + area + perimeter + compactness + width_of_kernel + assymetry_coefficient + length_of_kernel_groove\"\n",
    "model_3d = \"target ~ 1 + area + perimeter + length_of_kernel + width_of_kernel + assymetry_coefficient + length_of_kernel_groove\"\n",
    "model_3e = \"target ~ 1 + area + compactness + length_of_kernel + width_of_kernel + assymetry_coefficient + length_of_kernel_groove\"\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.glm.3a = glm(model_3a, data=iris.data)\n",
    "iris.glm.3b = glm(model_3b, data=iris.data)\n",
    "iris.glm.3c = glm(model_3c, data=iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"model_1\"           \"-4.87121487462612\"\n",
      "[1] \"model_2c\"          \"-9.31979403027607\"\n",
      "[1] \"model_3a\"         \"25.3174210943167\"\n",
      "[1] \"model_3b\"         \"15.4504250116728\"\n",
      "[1] \"model_3c\"         \"-5.0467304546584\"\n"
     ]
    }
   ],
   "source": [
    "print(c('model_1', BIC(iris.glm.1)))\n",
    "print(c('model_2c', BIC(iris.glm.2c )))\n",
    "print(c('model_3a', BIC(iris.glm.3a )))\n",
    "print(c('model_3b', BIC(iris.glm.3b )))\n",
    "print(c('model_3c', BIC(iris.glm.3c )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
